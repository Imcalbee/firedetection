{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb7e8254-bcaa-4c9d-aa7c-63dbb8375b7d",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c47cc5-4aa1-415f-808d-49c5f832db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov\n",
    "import ipywidgets as widgets\n",
    "import yaml\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics.utils.plotting import colors\n",
    "from typing import Tuple\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61910313-e041-47ac-9b00-97fc826047d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5bb2ed-a205-489d-84cf-c9b4fa3117b1",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab2ba3d-ed8f-4cb9-843e-89a3828e7024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240c5c7139bf4780a4835a1b3204b636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Device:', index=3, options=('CPU', 'GPU.0', 'GPU.1', 'AUTO'), value='AUTO')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "import openvino as ov\n",
    "\n",
    "core = ov.Core()\n",
    "\n",
    "device = widgets.Dropdown(\n",
    "    options=core.available_devices + [\"AUTO\"],\n",
    "    value=\"AUTO\",\n",
    "    description=\"Device:\",\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9369fc08-9265-4df9-8292-5624fe7c9ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Layer shape: [1,3,256,256]\n",
      "Output Layer shape: [1,6,1344]\n"
     ]
    }
   ],
   "source": [
    "model = core.read_model(model=\"models/best.xml\")\n",
    "compiled_model = core.compile_model(model = model, device_name = device.value)\n",
    "\n",
    "input_layer = compiled_model.input(0)\n",
    "output_layer = compiled_model.output(0)\n",
    "print(\"Input Layer shape:\", input_layer.shape)\n",
    "print(\"Output Layer shape:\", output_layer.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6be158-a11e-4418-9dff-dd7899d5bc63",
   "metadata": {},
   "source": [
    "# Import Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d414015c-a4ca-451c-914e-9daf2872dbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'fire', 1: 'smoke'}\n"
     ]
    }
   ],
   "source": [
    "with open('models/metadata.yaml') as info:\n",
    "    info_dict = yaml.load(info, Loader=yaml.Loader)\n",
    "\n",
    "labels = info_dict['names']\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f58ad3-98d0-4b9b-bbea-6277e2643a3c",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b583fd-85e3-45d3-92ce-ff377d354ecc",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09c2a380-ff70-4944-8230-6c0bdf9f9931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterbox(\n",
    "    img: np.ndarray,\n",
    "    new_shape: Tuple[int, int] = (640, 640),\n",
    "    color: Tuple[int, int, int] = (114, 114, 114),\n",
    "    auto: bool = False,\n",
    "    scale_fill: bool = False,\n",
    "    scaleup: bool = False,\n",
    "    stride: int = 32,\n",
    "):\n",
    "    \"\"\"\n",
    "    Resize image and padding for detection. Takes image as input,\n",
    "    resizes image to fit into new shape with saving original aspect ratio and pads it to meet stride-multiple constraints\n",
    "\n",
    "    Parameters:\n",
    "      img (np.ndarray): image for preprocessing\n",
    "      new_shape (Tuple(int, int)): image size after preprocessing in format [height, width]\n",
    "      color (Tuple(int, int, int)): color for filling padded area\n",
    "      auto (bool): use dynamic input size, only padding for stride constrins applied\n",
    "      scale_fill (bool): scale image to fill new_shape\n",
    "      scaleup (bool): allow scale image if it is lower then desired input size, can affect model accuracy\n",
    "      stride (int): input padding stride\n",
    "    Returns:\n",
    "      img (np.ndarray): image after preprocessing\n",
    "      ratio (Tuple(float, float)): hight and width scaling ratio\n",
    "      padding_size (Tuple(int, int)): height and width padding size\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = img.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better test mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    ratio = r, r  # width, height ratios\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "    elif scale_fill:  # stretch\n",
    "        dw, dh = 0.0, 0.0\n",
    "        new_unpad = (new_shape[1], new_shape[0])\n",
    "        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return img, ratio, (dw, dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f60340c-38c7-41bb-b65e-928ff1fd2b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(image, input_layer):\n",
    "    input_w, input_h = input_layer.shape[2], input_layer.shape[3]\n",
    "\n",
    "    input_image = letterbox(np.array(image))[0]\n",
    "    input_image = cv2.resize(input_image, (input_w, input_h))\n",
    "    input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n",
    "    input_image = input_image/255\n",
    "    input_image = input_image.transpose(2, 0, 1)\n",
    "    input_image = np.expand_dims(input_image, 0)\n",
    "\n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05b6e51-e0a0-49cf-b156-db5b1690f8dd",
   "metadata": {},
   "source": [
    "### Run Preprocessing and AI Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b0d2899-4a87-4c66-86ea-f62bd0738b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"images/test.jpg\")\n",
    "input_image = prepare_data(image, input_layer)\n",
    "print(np.shape(input_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c29c54ad-31e6-4749-8507-62279f2dee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = compiled_model([input_image])[output_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89f28c95-65de-4530-be83-76c35db4bf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[     13.592      20.519      21.183 ...      179.78      208.33      233.08]\n",
      "  [     16.219      12.081      7.4724 ...      235.69      224.86      214.69]\n",
      "  [     27.487      40.447      43.195 ...      217.93      262.06       157.5]\n",
      "  [     33.985      24.237       14.96 ...      263.96      303.89      245.01]\n",
      "  [ 3.3104e-05  5.6359e-05  3.4201e-05 ...  4.5266e-05  4.0379e-05   7.616e-05]\n",
      "  [ 9.1909e-05  8.7254e-05  3.5896e-05 ...  3.7759e-05  3.5953e-05  7.5515e-05]]]\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b180b118-118f-4928-8a3e-2ec7e7cfbb0e",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6774ea8-c001-400b-8be0-c4002ca72d47",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80f70879-a327-4252-89ab-b97f1151b25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(output, conf_threshold):\n",
    "\n",
    "    boxes = []\n",
    "    scores = []\n",
    "    label_key = []\n",
    "    label_index = 0\n",
    "\n",
    "    for class_ in output[0][4:]:\n",
    "        for index in range(len(class_)):\n",
    "            confidence = class_[index]\n",
    "\n",
    "            if confidence > conf_threshold:\n",
    "                xcen = output[0][0][index]\n",
    "                ycen = output[0][1][index]\n",
    "                w = output[0][2][index]\n",
    "                h =output[0][3][index]\n",
    "\n",
    "                xmin = int(xcen - (w/2))\n",
    "                xmax = int(xcen + (w/2))\n",
    "                ymin = int(ycen - (h/2))\n",
    "                ymax = int(ycen + (h/2))\n",
    "\n",
    "                box = (xmin, ymin, xmax, ymax)\n",
    "                boxes.append(box)\n",
    "                scores.append(confidence)\n",
    "                label_key.append(label_index)\n",
    "        label_index += 1\n",
    "\n",
    "    boxes = np.array(boxes)\n",
    "    scores = np.array(scores)\n",
    "\n",
    "    return boxes, scores, label_key\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c505f766-de25-40c3-bb8d-8ec9d899c06a",
   "metadata": {},
   "source": [
    "### Run Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e870242f-44de-4907-a9fc-828bb156fe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_threshold =.1\n",
    "boxes, scores, label_key = evaluate(output, conf_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e0e2a0f-cf11-4ec8-aef2-c518d537010b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106 146 166 208]\n",
      " [103 146 169 209]\n",
      " [103 146 169 209]\n",
      " [102 147 168 209]\n",
      " [102 146 168 209]\n",
      " [102 146 169 209]\n",
      " [103 147 168 209]\n",
      " [101 145 168 209]\n",
      " [101 145 168 209]\n",
      " [102 146 167 209]]\n",
      "[    0.20399     0.82178     0.86123     0.81731     0.86296      0.7983      0.8645     0.80706     0.85492     0.53587]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(boxes)\n",
    "print(scores)\n",
    "print(label_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ce7af8-d254-4126-8cff-da743d869b9e",
   "metadata": {},
   "source": [
    "### Non-Max Suppression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f5d6dd0-624a-4468-92e4-002c3471d5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(boxes, scores, conf_threshold):\t\n",
    "    assert boxes.shape[0] == scores.shape[0]\n",
    "    # bottom-left origin\n",
    "    ys1 = boxes[:, 0]\n",
    "    xs1 = boxes[:, 1]\n",
    "    # top-right target\n",
    "    ys2 = boxes[:, 2]\n",
    "    xs2 = boxes[:, 3]\n",
    "    # box coordinate ranges are inclusive-inclusive\n",
    "    areas = (ys2 - ys1) * (xs2 - xs1)\n",
    "    scores_indexes = scores.argsort().tolist()\n",
    "    boxes_keep_index = []\n",
    "    while len(scores_indexes):\n",
    "        index = scores_indexes.pop()\n",
    "        boxes_keep_index.append(index)\n",
    "        if not len(scores_indexes):\n",
    "            break\n",
    "        ious = compute_iou(boxes[index], boxes[scores_indexes], areas[index],\n",
    "                           areas[scores_indexes])\n",
    "        filtered_indexes = set((ious > conf_threshold).nonzero()[0])\n",
    "        # if there are no more scores_index\n",
    "        # then we should pop it\n",
    "        scores_indexes = [\n",
    "            v for (i, v) in enumerate(scores_indexes)\n",
    "            if i not in filtered_indexes\n",
    "        ]\n",
    "    return np.array(boxes_keep_index)\n",
    "\n",
    "\n",
    "def compute_iou(box, boxes, box_area, boxes_area):\n",
    "    # this is the iou of the box against all other boxes\n",
    "    assert boxes.shape[0] == boxes_area.shape[0]\n",
    "    # get all the origin-ys\n",
    "    # push up all the lower origin-xs, while keeping the higher origin-xs\n",
    "    ys1 = np.maximum(box[0], boxes[:, 0])\n",
    "    # get all the origin-xs\n",
    "    # push right all the lower origin-xs, while keeping higher origin-xs\n",
    "    xs1 = np.maximum(box[1], boxes[:, 1])\n",
    "    # get all the target-ys\n",
    "    # pull down all the higher target-ys, while keeping lower origin-ys\n",
    "    ys2 = np.minimum(box[2], boxes[:, 2])\n",
    "    # get all the target-xs\n",
    "    # pull left all the higher target-xs, while keeping lower target-xs\n",
    "    xs2 = np.minimum(box[3], boxes[:, 3])\n",
    "    # each intersection area is calculated by the\n",
    "    # pulled target-x minus the pushed origin-x\n",
    "    # multiplying\n",
    "    # pulled target-y minus the pushed origin-y\n",
    "    # we ignore areas where the intersection side would be negative\n",
    "    # this is done by using maxing the side length by 0\n",
    "    intersections = np.maximum(ys2 - ys1, 0) * np.maximum(xs2 - xs1, 0)\n",
    "    # each union is then the box area\n",
    "    # added to each other box area minusing their intersection calculated above\n",
    "    unions = box_area + boxes_area - intersections\n",
    "    # element wise division\n",
    "    # if the intersection is 0, then their ratio is 0\n",
    "    ious = intersections / unions\n",
    "    return ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73e24bc4-3c5e-44ec-93b3-e0b6a8a28642",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(boxes):\n",
    "    nms_output = non_max_suppression(boxes, scores, conf_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60a90063-031c-4b44-89eb-40d7324bee54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n"
     ]
    }
   ],
   "source": [
    "print(nms_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73ef294-e5da-46cc-a34b-e85f3c593de9",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73df5a4b-46d3-4f13-aa7c-5921b21345f3",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "023d40a9-fcf9-446e-bebf-a51dd7430ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(image, nms_output, boxes, label_key, scores, conf_threshold):\n",
    "    image_h, image_w, c = image.shape\n",
    "    input_w, input_h = input_layer.shape[2], input_layer.shape[3]\n",
    "\n",
    "    for i in nms_output:\n",
    "        xmin, ymin, xmax, ymax = boxes[i]\n",
    "        print(xmin, ymin, xmax, ymax)\n",
    "        \n",
    "        xmin = int(xmin*image_w/input_w)\n",
    "        xmax = int(xmax*image_w/input_w)\n",
    "        ymin = int(ymin*image_h/input_h)\n",
    "        ymax = int(ymax*image_h/input_h)\n",
    "\n",
    "        label = label_key[i]\n",
    "        color = colors(label)\n",
    "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color, 1)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        text = str(int(scores[i]*100)) + \"%\" +labels[label]\n",
    "        font_scale = (image_w/1000)\n",
    "        label_width, label_height = cv2.getTextSize(text, font, font_scale, 1)[0]\n",
    "        cv2.rectangle(image, (xmin, ymin-label_height), (xmin + label_width, ymin), color, 1)\n",
    "        \n",
    "        cv2.putText(image, text, (xmin, ymin), font, font_scale, (255,255,255), 1, cv2.LINE_AA)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130d0988-c23c-416c-b9b6-ffaf204c630c",
   "metadata": {},
   "source": [
    "# Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d18b76b-56a4-449c-93cd-dfc2ee7af91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image, conf_threshold):\n",
    "    input_image = prepare_data(image, input_layer)\n",
    "\n",
    "    start = time.time()\n",
    "    output = compiled_model([input_image])[output_layer]\n",
    "    end = time.time()\n",
    "\n",
    "    inference_time = end - start\n",
    "    \n",
    "    \n",
    "    boxes, scores, label_key = evaluate(output, conf_threshold)\n",
    "\n",
    "    \n",
    "    if len(boxes):\n",
    "        nms_output = non_max_suppression(boxes, scores, conf_threshold)\n",
    "        visualized_image = visualize(image, nms_output, boxes, label_key, scores, conf_threshold)\n",
    "\n",
    "        return visualized_image, inference_time\n",
    "    else:\n",
    "        return image, inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f014b47-e4e2-461e-ba56-57c21c87cb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.10.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "838cad6a-6999-4360-9916-eced1112066f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python==4.5.4.60\n",
      "  Using cached opencv-python-4.5.4.60.tar.gz (89.8 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  pip subprocess to install build dependencies did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [19 lines of output]\n",
      "  Ignoring numpy: markers 'python_version == \"3.6\" and platform_machine != \"aarch64\" and platform_machine != \"arm64\"' don't match your environment\n",
      "  Ignoring numpy: markers 'python_version == \"3.7\" and platform_machine != \"aarch64\" and platform_machine != \"arm64\"' don't match your environment\n",
      "  Ignoring numpy: markers 'python_version == \"3.8\" and platform_machine != \"aarch64\" and platform_machine != \"arm64\"' don't match your environment\n",
      "  Ignoring numpy: markers 'python_version <= \"3.9\" and sys_platform == \"linux\" and platform_machine == \"aarch64\"' don't match your environment\n",
      "  Ignoring numpy: markers 'python_version <= \"3.9\" and sys_platform == \"darwin\" and platform_machine == \"arm64\"' don't match your environment\n",
      "  Ignoring numpy: markers 'python_version == \"3.9\" and platform_machine != \"aarch64\" and platform_machine != \"arm64\"' don't match your environment\n",
      "  Collecting setuptools\n",
      "    Using cached setuptools-75.1.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Collecting wheel\n",
      "    Using cached wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Collecting scikit-build\n",
      "    Using cached scikit_build-0.18.1-py3-none-any.whl.metadata (18 kB)\n",
      "  Collecting cmake\n",
      "    Using cached cmake-3.30.3-py3-none-win_amd64.whl.metadata (6.4 kB)\n",
      "  Collecting pip\n",
      "    Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "  ERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\n",
      "  ERROR: Could not find a version that satisfies the requirement numpy==1.21.2 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4, 1.25.0, 1.25.1, 1.25.2, 1.26.0, 1.26.1, 1.26.2, 1.26.3, 1.26.4, 2.0.0, 2.0.1, 2.0.2, 2.1.0rc1, 2.1.0, 2.1.1)\n",
      "  ERROR: No matching distribution found for numpy==1.21.2\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "pip subprocess to install build dependencies did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python==4.5.4.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e05e9ec-5029-41e7-8e50-32ac46eb7f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 147 168 209\n",
      "0.005516767501831055\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"images/test.jpg\")\n",
    "conf_threshold = .15\n",
    "output_image,inference_time = predict_image(image, conf_threshold)\n",
    "\n",
    "print(inference_time)\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dc1df9-9bef-4905-8083-8586b7cb741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddBackground(frame, bg):\n",
    "    frame_h, frame_w = frame.shape[0], frame.shape[1]\n",
    "    new_h = 500\n",
    "    new_w = int((new_h/frame_h)*frame_w)\n",
    "    frame_resize = cv2.resize(frame, (new_w, new_h))\n",
    "\n",
    "    xmax = bg.shape[1]\n",
    "    ymax = bgimg.shape[0]\n",
    "    xmin = xmax - new_w\n",
    "    ymin = ymax - new_h\n",
    "\n",
    "    return bg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47aa91a-7ec0-48a8-a07e-c12113d8170b",
   "metadata": {},
   "source": [
    "## Live Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a963cdc2-d0b2-4cb2-9887-18b1515b3c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Main():\n",
    "    camera = cv2.VideoCapture(source)\n",
    "    inference_average =[]\n",
    "    bg = cv2.imread(background)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = camera.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        visualized_frame, inference_time = predict_image(frame, conf_threshold)\n",
    "        inference_average.append(inference_time)\n",
    "        deployment = AddBackground(frame, bg)\n",
    "        \n",
    "        cv2.imshow('Deployed Model', deployment))\n",
    "        cv2.imshow('Press Spacebar to Exit', visualized_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "            break\n",
    "    inf_ms = np.average(inference_average)*1000\n",
    "    print(\"The average inference time was \" + str(np.round(inf_ms,2))+\"milliseconds.\")\n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30882ed0-22f1-4278-9e53-4ade2b70a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"videos/test.mp4\"\n",
    "background = \"background.jpg\"\n",
    "conf_threshold = .4\n",
    "if __name__ == '__main__':\n",
    "    Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21379612-11e1-4463-bef2-d5a2a7902850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
