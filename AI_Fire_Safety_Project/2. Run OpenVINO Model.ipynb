{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb7e8254-bcaa-4c9d-aa7c-63dbb8375b7d",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5c47cc5-4aa1-415f-808d-49c5f832db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov\n",
    "import ipywidgets as widgets\n",
    "import yaml\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics.utils.plotting import colors\n",
    "from typing import Tuple\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61910313-e041-47ac-9b00-97fc826047d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.10.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5bb2ed-a205-489d-84cf-c9b4fa3117b1",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab2ba3d-ed8f-4cb9-843e-89a3828e7024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf9fac9554143be9294fb4e9a8e8768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Device:', index=3, options=('CPU', 'GPU.0', 'GPU.1', 'AUTO'), value='AUTO')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "import openvino as ov\n",
    "\n",
    "core = ov.Core()\n",
    "\n",
    "device = widgets.Dropdown(\n",
    "    options=core.available_devices + [\"AUTO\"],\n",
    "    value=\"AUTO\",\n",
    "    description=\"Device:\",\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9369fc08-9265-4df9-8292-5624fe7c9ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Layer shape: [1,3,256,256]\n",
      "Output Layer shape: [1,6,1344]\n"
     ]
    }
   ],
   "source": [
    "model = core.read_model(model=\"models/best.xml\")\n",
    "compiled_model = core.compile_model(model = model, device_name = device.value)\n",
    "\n",
    "input_layer = compiled_model.input(0)\n",
    "output_layer = compiled_model.output(0)\n",
    "print(\"Input Layer shape:\", input_layer.shape)\n",
    "print(\"Output Layer shape:\", output_layer.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6be158-a11e-4418-9dff-dd7899d5bc63",
   "metadata": {},
   "source": [
    "# Import Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d414015c-a4ca-451c-914e-9daf2872dbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'fire', 1: 'smoke'}\n"
     ]
    }
   ],
   "source": [
    "with open('models/metadata.yaml') as info:\n",
    "    info_dict = yaml.load(info, Loader=yaml.Loader)\n",
    "\n",
    "labels = info_dict['names']\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f58ad3-98d0-4b9b-bbea-6277e2643a3c",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b583fd-85e3-45d3-92ce-ff377d354ecc",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09c2a380-ff70-4944-8230-6c0bdf9f9931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterbox(\n",
    "    img: np.ndarray,\n",
    "    new_shape: Tuple[int, int] = (640, 640),\n",
    "    color: Tuple[int, int, int] = (114, 114, 114),\n",
    "    auto: bool = False,\n",
    "    scale_fill: bool = False,\n",
    "    scaleup: bool = False,\n",
    "    stride: int = 32,\n",
    "):\n",
    "    \"\"\"\n",
    "    Resize image and padding for detection. Takes image as input,\n",
    "    resizes image to fit into new shape with saving original aspect ratio and pads it to meet stride-multiple constraints\n",
    "\n",
    "    Parameters:\n",
    "      img (np.ndarray): image for preprocessing\n",
    "      new_shape (Tuple(int, int)): image size after preprocessing in format [height, width]\n",
    "      color (Tuple(int, int, int)): color for filling padded area\n",
    "      auto (bool): use dynamic input size, only padding for stride constrins applied\n",
    "      scale_fill (bool): scale image to fill new_shape\n",
    "      scaleup (bool): allow scale image if it is lower then desired input size, can affect model accuracy\n",
    "      stride (int): input padding stride\n",
    "    Returns:\n",
    "      img (np.ndarray): image after preprocessing\n",
    "      ratio (Tuple(float, float)): hight and width scaling ratio\n",
    "      padding_size (Tuple(int, int)): height and width padding size\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = img.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better test mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    ratio = r, r  # width, height ratios\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "    elif scale_fill:  # stretch\n",
    "        dw, dh = 0.0, 0.0\n",
    "        new_unpad = (new_shape[1], new_shape[0])\n",
    "        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return img, ratio, (dw, dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f60340c-38c7-41bb-b65e-928ff1fd2b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(image, input_layer):\n",
    "    input_w, input_h = input_layer.shape[2], input_layer.shape[3]\n",
    "\n",
    "    input_image = letterbox(np.array(image))[0]\n",
    "    input_image = cv2.resize(input_image, (input_w, input_h))\n",
    "    input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n",
    "    input_image = input_image/255\n",
    "    input_image = input_image.transpose(2, 0, 1)\n",
    "    input_image = np.expand_dims(input_image, 0)\n",
    "\n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05b6e51-e0a0-49cf-b156-db5b1690f8dd",
   "metadata": {},
   "source": [
    "### Run Preprocessing and AI Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b0d2899-4a87-4c66-86ea-f62bd0738b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"images/test.jpg\")\n",
    "input_image = prepare_data(image, input_layer)\n",
    "print(np.shape(input_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c29c54ad-31e6-4749-8507-62279f2dee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = compiled_model([input_image])[output_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89f28c95-65de-4530-be83-76c35db4bf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[     13.592      20.519      21.183 ...      179.78      208.33      233.08]\n",
      "  [     16.219      12.081      7.4724 ...      235.69      224.86      214.69]\n",
      "  [     27.487      40.447      43.195 ...      217.93      262.06       157.5]\n",
      "  [     33.985      24.237       14.96 ...      263.96      303.89      245.01]\n",
      "  [ 3.3104e-05  5.6359e-05  3.4201e-05 ...  4.5266e-05  4.0379e-05   7.616e-05]\n",
      "  [ 9.1909e-05  8.7254e-05  3.5896e-05 ...  3.7759e-05  3.5953e-05  7.5515e-05]]]\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b180b118-118f-4928-8a3e-2ec7e7cfbb0e",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6774ea8-c001-400b-8be0-c4002ca72d47",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80f70879-a327-4252-89ab-b97f1151b25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(output, conf_threshold):\n",
    "\n",
    "    boxes = []\n",
    "    scores = []\n",
    "    label_key = []\n",
    "    label_index = 0\n",
    "\n",
    "    for class_ in output[0][4:]:\n",
    "        for index in range(len(class_)):\n",
    "            confidence = class_[index]\n",
    "\n",
    "            if confidence > conf_threshold:\n",
    "                xcen = output[0][0][index]\n",
    "                ycen = output[0][1][index]\n",
    "                w = output[0][2][index]\n",
    "                h =output[0][3][index]\n",
    "\n",
    "                xmin = int(xcen - (w/2))\n",
    "                xmax = int(xcen + (w/2))\n",
    "                ymin = int(ycen - (h/2))\n",
    "                ymax = int(ycen + (h/2))\n",
    "\n",
    "                box = (xmin, ymin, xmax, ymax)\n",
    "                boxes.append(box)\n",
    "                scores.append(confidence)\n",
    "                label_key.append(label_index)\n",
    "        label_index += 1\n",
    "\n",
    "    boxes = np.array(boxes)\n",
    "    scores = np.array(scores)\n",
    "\n",
    "    return boxes, scores, label_key\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c505f766-de25-40c3-bb8d-8ec9d899c06a",
   "metadata": {},
   "source": [
    "### Run Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e870242f-44de-4907-a9fc-828bb156fe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_threshold =.1\n",
    "boxes, scores, label_key = evaluate(output, conf_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e0e2a0f-cf11-4ec8-aef2-c518d537010b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106 146 166 208]\n",
      " [103 146 169 209]\n",
      " [103 146 169 209]\n",
      " [102 147 168 209]\n",
      " [102 146 168 209]\n",
      " [102 146 169 209]\n",
      " [103 147 168 209]\n",
      " [101 145 168 209]\n",
      " [101 145 168 209]\n",
      " [102 146 167 209]]\n",
      "[    0.20399     0.82178     0.86123     0.81731     0.86296      0.7983      0.8645     0.80706     0.85492     0.53587]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(boxes)\n",
    "print(scores)\n",
    "print(label_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ce7af8-d254-4126-8cff-da743d869b9e",
   "metadata": {},
   "source": [
    "### Non-Max Suppression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f5d6dd0-624a-4468-92e4-002c3471d5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(boxes, scores, conf_threshold):\t\n",
    "    assert boxes.shape[0] == scores.shape[0]\n",
    "    # bottom-left origin\n",
    "    ys1 = boxes[:, 0]\n",
    "    xs1 = boxes[:, 1]\n",
    "    # top-right target\n",
    "    ys2 = boxes[:, 2]\n",
    "    xs2 = boxes[:, 3]\n",
    "    # box coordinate ranges are inclusive-inclusive\n",
    "    areas = (ys2 - ys1) * (xs2 - xs1)\n",
    "    scores_indexes = scores.argsort().tolist()\n",
    "    boxes_keep_index = []\n",
    "    while len(scores_indexes):\n",
    "        index = scores_indexes.pop()\n",
    "        boxes_keep_index.append(index)\n",
    "        if not len(scores_indexes):\n",
    "            break\n",
    "        ious = compute_iou(boxes[index], boxes[scores_indexes], areas[index],\n",
    "                           areas[scores_indexes])\n",
    "        filtered_indexes = set((ious > conf_threshold).nonzero()[0])\n",
    "        # if there are no more scores_index\n",
    "        # then we should pop it\n",
    "        scores_indexes = [\n",
    "            v for (i, v) in enumerate(scores_indexes)\n",
    "            if i not in filtered_indexes\n",
    "        ]\n",
    "    return np.array(boxes_keep_index)\n",
    "\n",
    "\n",
    "def compute_iou(box, boxes, box_area, boxes_area):\n",
    "    # this is the iou of the box against all other boxes\n",
    "    assert boxes.shape[0] == boxes_area.shape[0]\n",
    "    # get all the origin-ys\n",
    "    # push up all the lower origin-xs, while keeping the higher origin-xs\n",
    "    ys1 = np.maximum(box[0], boxes[:, 0])\n",
    "    # get all the origin-xs\n",
    "    # push right all the lower origin-xs, while keeping higher origin-xs\n",
    "    xs1 = np.maximum(box[1], boxes[:, 1])\n",
    "    # get all the target-ys\n",
    "    # pull down all the higher target-ys, while keeping lower origin-ys\n",
    "    ys2 = np.minimum(box[2], boxes[:, 2])\n",
    "    # get all the target-xs\n",
    "    # pull left all the higher target-xs, while keeping lower target-xs\n",
    "    xs2 = np.minimum(box[3], boxes[:, 3])\n",
    "    # each intersection area is calculated by the\n",
    "    # pulled target-x minus the pushed origin-x\n",
    "    # multiplying\n",
    "    # pulled target-y minus the pushed origin-y\n",
    "    # we ignore areas where the intersection side would be negative\n",
    "    # this is done by using maxing the side length by 0\n",
    "    intersections = np.maximum(ys2 - ys1, 0) * np.maximum(xs2 - xs1, 0)\n",
    "    # each union is then the box area\n",
    "    # added to each other box area minusing their intersection calculated above\n",
    "    unions = box_area + boxes_area - intersections\n",
    "    # element wise division\n",
    "    # if the intersection is 0, then their ratio is 0\n",
    "    ious = intersections / unions\n",
    "    return ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73e24bc4-3c5e-44ec-93b3-e0b6a8a28642",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(boxes):\n",
    "    nms_output = non_max_suppression(boxes, scores, conf_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60a90063-031c-4b44-89eb-40d7324bee54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n"
     ]
    }
   ],
   "source": [
    "print(nms_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73ef294-e5da-46cc-a34b-e85f3c593de9",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73df5a4b-46d3-4f13-aa7c-5921b21345f3",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "023d40a9-fcf9-446e-bebf-a51dd7430ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(image, nms_output, boxes, label_key, scores, conf_threshold):\n",
    "    image_h, image_w, c = image.shape\n",
    "    input_w, input_h = input_layer.shape[2], input_layer.shape[3]\n",
    "\n",
    "    for i in nms_output:\n",
    "        xmin, ymin, xmax, ymax = boxes[i]\n",
    "        print(xmin, ymin, xmax, ymax)\n",
    "        \n",
    "        xmin = int(xmin*image_w/input_w)\n",
    "        xmax = int(xmax*image_w/input_w)\n",
    "        ymin = int(ymin*image_h/input_h)\n",
    "        ymax = int(ymax*image_h/input_h)\n",
    "\n",
    "        label = label_key[i]\n",
    "        color = colors(label)\n",
    "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color, 1)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        text = str(int(scores[i]*100)) + \"%\" +labels[label]\n",
    "        font_scale = (image_w/1000)\n",
    "        label_width, label_height = cv2.getTextSize(text, font, font_scale, 1)[0]\n",
    "        cv2.rectangle(image, (xmin, ymin-label_height), (xmin + label_width, ymin), color, 1)\n",
    "        \n",
    "        cv2.putText(image, text, (xmin, ymin), font, font_scale, (255,255,255), 1, cv2.LINE_AA)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130d0988-c23c-416c-b9b6-ffaf204c630c",
   "metadata": {},
   "source": [
    "# Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d18b76b-56a4-449c-93cd-dfc2ee7af91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image, conf_threshold):\n",
    "    input_image = prepare_data(image, input_layer)\n",
    "\n",
    "    start = time.time()\n",
    "    output = compiled_model([input_image])[output_layer]\n",
    "    end = time.time()\n",
    "\n",
    "    inference_time = end - start\n",
    "    \n",
    "    \n",
    "    boxes, scores, label_key = evaluate(output, conf_threshold)\n",
    "\n",
    "    \n",
    "    if len(boxes):\n",
    "        nms_output = non_max_suppression(boxes, scores, conf_threshold)\n",
    "        visualized_image = visualize(image, nms_output, boxes, label_key, scores, conf_threshold)\n",
    "\n",
    "        return visualized_image, inference_time\n",
    "    else:\n",
    "        return image, inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f014b47-e4e2-461e-ba56-57c21c87cb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.10.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e05e9ec-5029-41e7-8e50-32ac46eb7f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 147 168 209\n",
      "0.007625102996826172\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"images/test.jpg\")\n",
    "conf_threshold = .15\n",
    "output_image,inference_time = predict_image(image, conf_threshold)\n",
    "\n",
    "print(inference_time)\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12dc1df9-9bef-4905-8083-8586b7cb741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddBackground(frame, bg):\n",
    "    frame_h, frame_w = frame.shape[0], frame.shape[1]\n",
    "    new_h = 500\n",
    "    new_w = int((new_h/frame_h)*frame_w)\n",
    "    frame_resize = cv2.resize(frame, (new_w, new_h))\n",
    "\n",
    "    xmax = bg.shape[1]\n",
    "    ymax = bg.shape[0]\n",
    "    xmin = xmax - new_w\n",
    "    ymin = ymax - new_h\n",
    "\n",
    "    return bg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47aa91a-7ec0-48a8-a07e-c12113d8170b",
   "metadata": {},
   "source": [
    "## Live Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a963cdc2-d0b2-4cb2-9887-18b1515b3c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Main():\n",
    "    camera = cv2.VideoCapture(source)\n",
    "    inference_average =[]\n",
    "    bg = cv2.imread(background)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = camera.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        visualized_frame, inference_time = predict_image(frame, conf_threshold)\n",
    "        inference_average.append(inference_time)\n",
    "        deployment = AddBackground(frame, bg)\n",
    "        \n",
    "        cv2.imshow('Deployed Model', deployment)\n",
    "        cv2.imshow('Press Spacebar to Exit', visualized_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "            break\n",
    "    inf_ms = np.average(inference_average)*1000\n",
    "    print(\"The average inference time was \" + str(np.round(inf_ms,2))+\"milliseconds.\")\n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30882ed0-22f1-4278-9e53-4ade2b70a1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 139 210 197\n",
      "40 142 82 195\n",
      "110 133 208 195\n",
      "178 139 210 197\n",
      "40 142 82 195\n",
      "110 133 208 195\n",
      "113 74 159 126\n",
      "37 143 78 175\n",
      "109 131 210 196\n",
      "108 78 210 194\n",
      "174 144 211 198\n",
      "109 89 171 195\n",
      "179 144 213 198\n",
      "110 136 214 197\n",
      "49 145 78 195\n",
      "111 74 156 125\n",
      "108 126 209 196\n",
      "49 143 81 196\n",
      "46 145 78 194\n",
      "109 59 210 195\n",
      "111 129 208 196\n",
      "109 134 208 196\n",
      "176 137 210 197\n",
      "107 64 165 125\n",
      "175 155 210 197\n",
      "117 95 141 124\n",
      "174 151 211 197\n",
      "116 92 157 125\n",
      "176 144 211 197\n",
      "112 78 164 125\n",
      "109 98 127 127\n",
      "109 124 211 197\n",
      "175 142 210 197\n",
      "109 137 210 196\n",
      "110 77 159 123\n",
      "110 135 210 196\n",
      "111 80 162 124\n",
      "43 157 79 196\n",
      "110 132 208 196\n",
      "120 61 163 126\n",
      "112 130 210 196\n",
      "175 152 210 197\n",
      "176 145 210 198\n",
      "110 87 156 126\n",
      "115 63 160 125\n",
      "113 127 209 196\n",
      "34 133 69 173\n",
      "177 142 212 197\n",
      "112 131 212 196\n",
      "110 131 212 197\n",
      "110 77 149 127\n",
      "109 75 214 195\n",
      "47 155 75 195\n",
      "108 130 217 196\n",
      "176 148 215 198\n",
      "45 151 75 195\n",
      "108 138 219 196\n",
      "178 140 219 197\n",
      "44 142 74 195\n",
      "109 86 130 125\n",
      "108 129 214 197\n",
      "45 157 80 196\n",
      "114 89 163 122\n",
      "44 151 74 196\n",
      "111 133 212 196\n",
      "111 127 211 197\n",
      "114 78 162 126\n",
      "175 139 211 197\n",
      "110 84 161 127\n",
      "108 137 211 197\n",
      "110 131 211 196\n",
      "104 64 145 123\n",
      "46 137 76 194\n",
      "118 65 159 125\n",
      "176 144 211 198\n",
      "175 142 210 197\n",
      "112 137 210 196\n",
      "120 55 160 125\n",
      "111 134 209 196\n",
      "118 64 156 126\n",
      "177 144 210 198\n",
      "119 65 162 122\n",
      "177 140 210 197\n",
      "47 148 77 196\n",
      "110 132 210 196\n",
      "175 143 210 197\n",
      "119 68 156 120\n",
      "47 155 75 196\n",
      "110 138 210 195\n",
      "177 147 210 197\n",
      "45 144 76 196\n",
      "177 144 210 197\n",
      "109 134 211 197\n",
      "41 154 76 196\n",
      "108 73 166 124\n",
      "115 74 164 123\n",
      "177 139 211 197\n",
      "176 144 211 197\n",
      "111 76 165 123\n",
      "176 141 210 197\n",
      "120 70 155 125\n",
      "110 130 210 195\n",
      "37 147 72 195\n",
      "174 135 211 198\n",
      "93 73 211 195\n",
      "46 153 78 196\n",
      "177 140 210 197\n",
      "44 149 76 196\n",
      "109 137 212 197\n",
      "176 138 212 197\n",
      "116 74 163 128\n",
      "175 147 210 197\n",
      "118 81 164 123\n",
      "120 66 162 121\n",
      "176 135 210 197\n",
      "111 136 209 196\n",
      "43 145 68 176\n",
      "122 66 161 124\n",
      "40 135 69 175\n",
      "173 129 209 197\n",
      "111 129 212 196\n",
      "111 130 208 195\n",
      "41 136 76 174\n",
      "175 132 209 198\n",
      "39 148 74 175\n",
      "176 140 210 197\n",
      "110 142 209 196\n",
      "133 60 158 112\n",
      "118 69 157 126\n",
      "111 124 209 197\n",
      "111 134 210 196\n",
      "116 63 160 122\n",
      "111 134 207 196\n",
      "45 151 75 191\n",
      "177 124 211 197\n",
      "110 122 212 196\n",
      "175 147 210 198\n",
      "119 86 166 126\n",
      "117 81 158 125\n",
      "177 150 210 198\n",
      "176 143 210 197\n",
      "176 144 210 198\n",
      "49 140 77 182\n",
      "177 135 208 198\n",
      "177 133 209 197\n",
      "176 137 210 197\n",
      "113 70 157 126\n",
      "117 69 164 128\n",
      "178 144 210 198\n",
      "182 151 209 198\n",
      "112 85 155 128\n",
      "177 140 211 197\n",
      "177 126 211 197\n",
      "117 84 162 120\n",
      "173 138 210 197\n",
      "107 134 209 197\n",
      "109 135 208 196\n",
      "174 137 207 198\n",
      "109 75 163 121\n",
      "176 135 208 198\n",
      "110 132 208 196\n",
      "120 72 159 125\n",
      "175 154 210 198\n",
      "119 60 155 126\n",
      "34 135 62 175\n",
      "108 93 168 195\n",
      "177 135 211 197\n",
      "41 151 73 194\n",
      "40 155 73 195\n",
      "175 136 210 197\n",
      "101 81 150 125\n",
      "117 69 154 125\n",
      "45 156 77 196\n",
      "112 125 210 197\n",
      "43 154 75 196\n",
      "118 64 158 123\n",
      "115 73 159 127\n",
      "110 127 210 196\n",
      "177 149 210 198\n",
      "178 138 211 197\n",
      "107 134 210 196\n",
      "182 130 211 198\n",
      "111 90 154 125\n",
      "109 62 155 133\n",
      "134 59 161 115\n",
      "111 132 211 196\n",
      "119 65 158 124\n",
      "180 129 213 198\n",
      "118 79 155 125\n",
      "37 143 76 197\n",
      "177 146 211 198\n",
      "117 69 157 124\n",
      "111 133 212 196\n",
      "176 136 210 198\n",
      "47 151 80 195\n",
      "177 151 211 197\n",
      "116 73 158 126\n",
      "44 147 78 179\n",
      "110 149 208 196\n",
      "177 145 211 197\n",
      "43 145 76 180\n",
      "103 79 198 195\n",
      "104 70 157 125\n",
      "175 144 210 197\n",
      "109 141 209 196\n",
      "115 71 161 127\n",
      "109 90 209 196\n",
      "42 150 77 192\n",
      "177 147 210 198\n",
      "41 148 78 191\n",
      "178 147 210 198\n",
      "107 72 188 195\n",
      "108 133 210 196\n",
      "109 134 210 195\n",
      "111 72 162 125\n",
      "46 144 80 194\n",
      "110 122 210 196\n",
      "117 70 169 125\n",
      "111 129 212 197\n",
      "44 147 76 185\n",
      "109 107 213 195\n",
      "115 82 162 124\n",
      "182 142 212 198\n",
      "113 88 159 128\n",
      "181 140 214 198\n",
      "112 70 160 126\n",
      "182 155 210 197\n",
      "183 150 210 198\n",
      "112 68 159 128\n",
      "110 136 211 196\n",
      "46 151 75 196\n",
      "108 78 164 125\n",
      "179 146 209 198\n",
      "105 79 157 123\n",
      "45 139 70 196\n",
      "115 73 158 124\n",
      "110 141 208 196\n",
      "45 125 70 173\n",
      "177 146 209 198\n",
      "209 152 255 178\n",
      "45 158 76 196\n",
      "110 133 210 195\n",
      "46 155 74 195\n",
      "118 61 159 126\n",
      "109 120 209 197\n",
      "178 148 210 198\n",
      "109 131 210 196\n",
      "110 89 151 125\n",
      "180 148 211 198\n",
      "173 139 211 197\n",
      "47 158 75 196\n",
      "56 76 215 194\n",
      "109 69 157 126\n",
      "111 127 211 196\n",
      "175 150 211 197\n",
      "177 149 210 197\n",
      "109 129 209 196\n",
      "110 72 160 128\n",
      "110 77 157 125\n",
      "179 136 212 197\n",
      "121 85 169 123\n",
      "176 132 211 198\n",
      "46 157 73 195\n",
      "117 65 165 126\n",
      "176 151 210 197\n",
      "114 80 162 126\n",
      "110 80 211 195\n",
      "116 85 152 124\n",
      "177 137 210 197\n",
      "110 134 208 196\n",
      "48 155 75 196\n",
      "177 136 207 197\n",
      "111 66 152 126\n",
      "47 156 77 196\n",
      "112 69 155 127\n",
      "46 148 76 196\n",
      "176 142 210 198\n",
      "117 79 151 124\n",
      "110 134 209 196\n",
      "48 151 73 196\n",
      "48 136 72 196\n",
      "176 142 210 197\n",
      "47 152 74 196\n",
      "110 91 209 196\n",
      "177 142 211 197\n",
      "46 158 73 195\n",
      "111 134 209 196\n",
      "174 148 211 197\n",
      "116 74 148 126\n",
      "45 154 75 195\n",
      "46 156 75 195\n",
      "174 136 209 198\n",
      "119 78 163 125\n",
      "48 153 74 195\n",
      "178 146 210 198\n",
      "116 75 158 126\n",
      "49 147 74 196\n",
      "111 131 208 196\n",
      "106 74 161 126\n",
      "177 137 207 198\n",
      "49 152 73 195\n",
      "176 138 211 197\n",
      "109 130 211 196\n",
      "110 79 161 124\n",
      "109 140 211 196\n",
      "177 144 211 198\n",
      "110 128 210 195\n",
      "119 79 165 124\n",
      "178 158 210 198\n",
      "47 160 76 196\n",
      "178 148 210 198\n",
      "123 68 162 124\n",
      "180 138 220 198\n",
      "116 69 164 125\n",
      "110 131 215 196\n",
      "110 71 161 121\n",
      "112 134 210 196\n",
      "49 151 79 195\n",
      "180 136 209 197\n",
      "49 154 75 196\n",
      "178 136 215 197\n",
      "177 145 211 198\n",
      "52 135 83 197\n",
      "108 140 216 197\n",
      "177 142 217 198\n",
      "49 145 80 196\n",
      "177 141 214 198\n",
      "111 133 216 196\n",
      "49 141 69 180\n",
      "110 147 213 197\n",
      "52 142 76 173\n",
      "177 147 212 198\n",
      "52 146 77 172\n",
      "176 147 212 198\n",
      "109 131 214 196\n",
      "110 129 215 196\n",
      "114 74 154 125\n",
      "51 155 76 194\n",
      "115 64 163 124\n",
      "51 154 75 195\n",
      "110 129 214 196\n",
      "177 149 214 198\n",
      "51 150 79 196\n",
      "182 143 213 198\n",
      "110 137 219 196\n",
      "177 148 211 198\n",
      "120 63 155 123\n",
      "51 143 72 193\n",
      "115 74 162 124\n",
      "177 144 211 197\n",
      "176 143 211 197\n",
      "128 68 163 128\n",
      "49 143 73 196\n",
      "178 155 210 197\n",
      "48 150 71 196\n",
      "178 149 211 198\n",
      "176 143 212 197\n",
      "48 151 72 195\n",
      "112 65 159 126\n",
      "176 144 215 198\n",
      "48 149 73 196\n",
      "117 73 166 127\n",
      "110 137 211 196\n",
      "49 151 77 194\n",
      "180 137 213 198\n",
      "110 126 209 197\n",
      "117 87 161 124\n",
      "47 152 75 196\n",
      "110 142 209 196\n",
      "177 151 210 197\n",
      "174 143 211 197\n",
      "45 145 73 196\n",
      "42 147 75 197\n",
      "45 155 76 196\n",
      "117 67 162 125\n",
      "109 133 208 196\n",
      "177 144 210 198\n",
      "179 139 210 197\n",
      "109 134 209 196\n",
      "110 129 209 196\n",
      "176 128 213 198\n",
      "117 76 158 124\n",
      "48 139 72 196\n",
      "118 61 151 129\n",
      "119 62 155 124\n",
      "47 151 78 196\n",
      "116 57 153 126\n",
      "177 137 213 197\n",
      "111 134 212 197\n",
      "49 139 70 174\n",
      "177 128 211 197\n",
      "175 127 213 198\n",
      "48 157 74 195\n",
      "117 62 168 124\n",
      "178 144 212 198\n",
      "48 159 74 196\n",
      "177 138 210 197\n",
      "116 66 161 125\n",
      "48 155 77 194\n",
      "49 152 73 195\n",
      "177 135 207 198\n",
      "177 137 208 198\n",
      "107 74 214 195\n",
      "51 142 74 181\n",
      "109 67 210 195\n",
      "177 144 211 198\n",
      "117 91 165 123\n",
      "181 137 212 198\n",
      "177 152 211 197\n",
      "119 81 155 124\n",
      "49 160 73 195\n",
      "177 145 210 198\n",
      "115 66 154 128\n",
      "47 154 77 196\n",
      "109 130 213 196\n",
      "50 145 74 195\n",
      "120 75 156 124\n",
      "119 77 159 121\n",
      "176 144 210 198\n",
      "49 149 80 192\n",
      "175 145 210 198\n",
      "114 77 150 129\n",
      "109 146 209 195\n",
      "48 155 78 196\n",
      "178 144 210 198\n",
      "46 155 73 196\n",
      "109 129 211 196\n",
      "47 154 72 195\n",
      "174 137 209 198\n",
      "47 160 75 196\n",
      "109 128 209 196\n",
      "110 79 170 127\n",
      "117 79 163 124\n",
      "176 144 211 198\n",
      "47 142 74 196\n",
      "107 77 166 123\n",
      "175 155 211 197\n",
      "118 64 162 123\n",
      "48 149 79 196\n",
      "175 150 210 197\n",
      "49 150 79 196\n",
      "47 151 79 196\n",
      "176 133 209 198\n",
      "110 132 211 196\n",
      "45 153 78 196\n",
      "116 79 164 122\n",
      "175 144 210 198\n",
      "45 154 74 196\n",
      "117 69 165 123\n",
      "46 146 75 196\n",
      "109 132 209 196\n",
      "176 138 211 197\n",
      "119 69 157 124\n",
      "45 155 74 196\n",
      "118 62 155 125\n",
      "44 157 77 196\n",
      "111 129 210 195\n",
      "45 156 75 195\n",
      "177 143 211 198\n",
      "119 93 158 124\n",
      "47 160 76 196\n",
      "111 125 211 196\n",
      "48 148 74 195\n",
      "177 144 211 197\n",
      "109 74 157 123\n",
      "47 139 74 196\n",
      "110 132 209 196\n",
      "175 133 210 197\n",
      "47 157 74 196\n",
      "178 133 211 197\n",
      "117 70 171 127\n",
      "46 147 73 195\n",
      "176 137 210 197\n",
      "110 136 210 197\n",
      "116 67 164 126\n",
      "174 148 210 197\n",
      "45 139 75 195\n",
      "117 75 161 123\n",
      "117 71 162 124\n",
      "176 144 211 198\n",
      "111 134 209 196\n",
      "45 156 72 194\n",
      "178 134 211 197\n",
      "112 129 208 196\n",
      "48 154 73 195\n",
      "174 148 210 197\n",
      "46 157 78 196\n",
      "175 150 210 197\n",
      "47 148 75 196\n",
      "111 145 209 195\n",
      "116 76 155 126\n",
      "111 136 210 196\n",
      "46 141 70 178\n",
      "117 66 165 125\n",
      "179 143 211 198\n",
      "46 155 75 194\n",
      "111 134 212 196\n",
      "179 136 211 197\n",
      "175 143 211 198\n",
      "119 72 158 123\n",
      "112 135 213 196\n",
      "48 150 77 189\n",
      "178 155 211 197\n",
      "111 125 210 196\n",
      "43 152 76 196\n",
      "178 145 211 198\n",
      "108 133 224 196\n",
      "108 131 214 197\n",
      "175 138 211 198\n",
      "139 71 169 112\n",
      "176 142 210 197\n",
      "124 64 159 122\n",
      "44 149 75 195\n",
      "177 144 210 198\n",
      "46 150 75 196\n",
      "118 64 161 124\n",
      "111 134 210 196\n",
      "177 151 210 197\n",
      "46 148 77 196\n",
      "119 62 156 123\n",
      "111 148 209 196\n",
      "109 137 208 196\n",
      "48 156 79 197\n",
      "110 76 158 129\n",
      "110 130 208 196\n",
      "48 159 77 196\n",
      "107 64 156 124\n",
      "49 161 74 196\n",
      "111 138 209 196\n",
      "175 137 211 197\n",
      "50 156 75 196\n",
      "110 137 209 196\n",
      "176 138 210 197\n",
      "The average inference time was 4.88milliseconds.\n"
     ]
    }
   ],
   "source": [
    "source = \"videos/test.mp4\"\n",
    "background = \"background.jpg\"\n",
    "conf_threshold = .4\n",
    "if __name__ == '__main__':\n",
    "    Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21379612-11e1-4463-bef2-d5a2a7902850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
